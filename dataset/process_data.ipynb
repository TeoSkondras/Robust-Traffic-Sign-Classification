{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b0ff9d",
   "metadata": {},
   "source": [
    "# Kaggle Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd37b2",
   "metadata": {},
   "source": [
    "## Setup: Install kagglehub\n",
    "This cell installs the `kagglehub` helper used to fetch datasets directly into the notebook environment. Run this first to ensure the download cells work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e352a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralized imports for the notebook (moved here to avoid duplicates)\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdeee1",
   "metadata": {},
   "source": [
    "## Download traffic sign classification dataset\n",
    "This cell downloads the traffic sign classification dataset. It will print the path where the dataset was stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a169a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ahemateja19bec1025/traffic-sign-dataset-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a20dc",
   "metadata": {},
   "source": [
    "## Download car detection dataset\n",
    "This cell downloads a second dataset (car detection). We fetch both datasets so we can later combine relevant images for training/analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"pkdarabi/cardetection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb98aa0",
   "metadata": {},
   "source": [
    "# Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e96400",
   "metadata": {},
   "source": [
    "## Build mapping for Dataset 2 (image path -> human-readable label)\n",
    "This block reads the provided CSV label file and constructs a dictionary mapping absolute image paths to their human-readable labels. It handles both training folders (labeled by subdirectory) and the TEST folder (filenames contain class id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary mapping absolute image path -> human-readable label\n",
    "\n",
    "root = Path(r\"dataset2/traffic_Data\")\n",
    "labels_csv = Path(r\"dataset2/labels.csv\")\n",
    "\n",
    "# Load label mapping (ClassId -> Name)\n",
    "label_map = {}\n",
    "with labels_csv.open(newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        cid = str(row['ClassId']).strip()\n",
    "        label_map[cid] = row['Name'].strip()\n",
    "\n",
    "# Helper to extract class id from test filename (before first underscore)\n",
    "def extract_test_class_id(filename: str) -> str:\n",
    "    first = filename.split('_', 1)[0]\n",
    "    # Remove leading zeros consistently (keep original mapping style if needed)\n",
    "    # Our labels.csv uses non-padded integers, so normalize.\n",
    "    try:\n",
    "        return str(int(first))\n",
    "    except ValueError:\n",
    "        return first  # fallback\n",
    "\n",
    "data_label_map = {}\n",
    "\n",
    "# Process training data (DATA folder: subdirectories named by class id)\n",
    "train_dir = root / 'DATA'\n",
    "if train_dir.exists():\n",
    "    for class_dir in sorted([d for d in train_dir.iterdir() if d.is_dir()]):\n",
    "        class_id = class_dir.name  # e.g. '0', '1', '10', ...\n",
    "        human_label = label_map.get(class_id, f\"<UNKNOWN:{class_id}>\")\n",
    "        for img_path in class_dir.rglob('*'):\n",
    "            if img_path.is_file() and img_path.suffix.lower() in {'.png', '.jpg', '.jpeg'}:\n",
    "                data_label_map[str(img_path.resolve())] = human_label\n",
    "\n",
    "# Process test data (files in TEST folder; first token before '_' is zero-padded class id)\n",
    "test_dir = root / 'TEST'\n",
    "if test_dir.exists():\n",
    "    for img_path in sorted([p for p in test_dir.iterdir() if p.is_file()]):\n",
    "        class_id_norm = extract_test_class_id(img_path.name)\n",
    "        human_label = label_map.get(class_id_norm, f\"<UNKNOWN:{class_id_norm}>\")\n",
    "        data_label_map[str(img_path.resolve())] = human_label\n",
    "\n",
    "print(f\"Total datapoints collected: {len(data_label_map)}\")\n",
    "# Show a small sample\n",
    "sample_items = list(data_label_map.items())[:10]\n",
    "for p, lbl in sample_items:\n",
    "    print(p, '->', lbl)\n",
    "\n",
    "# Optionally keep the dictionary for later use\n",
    "all_data_label_map = data_label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a911dcb",
   "metadata": {},
   "source": [
    "## Clean: remove unknown labels\n",
    "Filter out any examples whose label begins with `Unknown` to remove unlabeled or suspect data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd23919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#throw away all data with labels starting with Unknown (exact caps)\n",
    "all_data_label_map = {p: lbl for p, lbl in all_data_label_map.items() if not lbl.startswith(\"Unknown\")}\n",
    "print(f\"Total datapoints after cleaning: {len(all_data_label_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e7496",
   "metadata": {},
   "source": [
    "## Save dataset2 mappings to JSON\n",
    "Persist both the image->label mapping and the class-id->name mapping so downstream cells and scripts can reuse them without recomputing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as a json file\n",
    "\n",
    "with open('dataset2_labels.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_data_label_map, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#also go to the dataset2/labels.csv where we have ClassId,Name -> and save another json file based on our label_map\n",
    "file_path = 'dataset2/labels.csv'\n",
    "label_map = {}\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        cid = str(row['ClassId']).strip()\n",
    "        label_map[cid] = row['Name'].strip()\n",
    "with open('label_map.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(label_map, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a2167",
   "metadata": {},
   "source": [
    "## EDA: image dimension distributions (Dataset 2)\n",
    "Sample a subset of images and plot width/height distributions to decide a target resolution for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do an eda o the dimensions of all images, show some stats and plots\n",
    "\n",
    "with open('dataset2_labels.json', 'r', encoding='utf-8') as f:\n",
    "    all_data_label_map = json.load(f)\n",
    "    \n",
    "sample_paths = random.sample(list(all_data_label_map.keys()), 5000)\n",
    "dimensions = []\n",
    "for path in sample_paths:\n",
    "    with Image.open(path) as img:\n",
    "        dimensions.append(img.size)  # (width, height)\n",
    "widths, heights = zip(*dimensions)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Image Width Distribution')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=20, color='green', alpha=0.7)\n",
    "plt.title('Image Height Distribution')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52881390",
   "metadata": {},
   "source": [
    "* Here it seems that either 128x128 or 256*256 is used.\n",
    "* Let's use 256x256 so that we don't lose details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale all dataset2 images to 256x256\n",
    "\n",
    "TARGET_SIZE = 256\n",
    "\n",
    "# Load current labels\n",
    "with open('dataset2_labels.json', 'r', encoding='utf-8') as f:\n",
    "    dataset2_labels = json.load(f)\n",
    "\n",
    "output_dir = Path(r\"dataset2_processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def process_image(img: Image.Image, target_size: int = 256) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Resize image to target_size x target_size.\n",
    "    - If larger: center crop\n",
    "    - If smaller: pad with reflection\n",
    "    - If one dimension matches, handle accordingly\n",
    "    \"\"\"\n",
    "    width, height = img.size\n",
    "    \n",
    "    if width == target_size and height == target_size:\n",
    "        return img.copy()\n",
    "    \n",
    "    # If image is larger in both dimensions, center crop\n",
    "    if width >= target_size and height >= target_size:\n",
    "        left = (width - target_size) // 2\n",
    "        top = (height - target_size) // 2\n",
    "        return img.crop((left, top, left + target_size, top + target_size))\n",
    "    \n",
    "    # If image is smaller in at least one dimension, we need to pad\n",
    "    # First, if one dimension is larger, crop that dimension to target\n",
    "    if width > target_size:\n",
    "        left = (width - target_size) // 2\n",
    "        img = img.crop((left, 0, left + target_size, height))\n",
    "        width = target_size\n",
    "    if height > target_size:\n",
    "        top = (height - target_size) // 2\n",
    "        img = img.crop((0, top, width, top + target_size))\n",
    "        height = target_size\n",
    "    \n",
    "    # Now pad to target size using reflection padding\n",
    "    pad_left = (target_size - width) // 2\n",
    "    pad_right = target_size - width - pad_left\n",
    "    pad_top = (target_size - height) // 2\n",
    "    pad_bottom = target_size - height - pad_top\n",
    "    \n",
    "    # For reflection padding use numpy (available from top imports)\n",
    "    try:\n",
    "        img_array = np.array(img)\n",
    "        # Pad with reflect mode\n",
    "        if len(img_array.shape) == 3:\n",
    "            padded = np.pad(img_array, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode='reflect')\n",
    "        else:\n",
    "            padded = np.pad(img_array, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='reflect')\n",
    "        return Image.fromarray(padded)\n",
    "    except Exception:\n",
    "        # Fallback: use edge expansion (less ideal but works)\n",
    "        return ImageOps.expand(img, border=(pad_left, pad_top, pad_right, pad_bottom), fill='black')\n",
    "\n",
    "# Process all images\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "updated_labels = {}\n",
    "\n",
    "for img_path_str, label in dataset2_labels.items():\n",
    "    img_path = Path(img_path_str)\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        error_count += 1\n",
    "        print(f\"Missing: {img_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            # Convert to RGB if necessary (some images might be grayscale or RGBA)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            processed = process_image(img, TARGET_SIZE)\n",
    "            \n",
    "            # Save with same filename to output directory\n",
    "            output_path = output_dir / img_path.name\n",
    "            processed.save(output_path)\n",
    "            \n",
    "            # Update path in labels\n",
    "            updated_labels[str(output_path.resolve())] = label\n",
    "            success_count += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_count += 1\n",
    "        print(f\"Error processing {img_path.name}: {e}\")\n",
    "\n",
    "# Save updated labels\n",
    "with open('dataset2_labels.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(updated_labels, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Successfully processed: {success_count}\")\n",
    "print(f\"Errors: {error_count}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Updated dataset2_labels.json with new paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057c6b2",
   "metadata": {},
   "source": [
    "## Verify processed image dimensions (Dataset 2)\n",
    "Plot the distributions again after processing to make sure images are now uniform (256x256)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the distribution of image dimensions in the cropped dataset2_labels.json\n",
    "\n",
    "with open('dataset2_labels.json', 'r', encoding='utf-8') as f:\n",
    "    dataset2_labels = json.load(f)\n",
    "sample_paths = random.sample(list(dataset2_labels.keys()), 5000)\n",
    "dimensions = []\n",
    "for path in sample_paths:\n",
    "    with Image.open(path) as img:\n",
    "        dimensions.append(img.size)  # (width, height)\n",
    "widths, heights = zip(*dimensions)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(widths, bins=50, alpha=0.7, label='Widths')\n",
    "plt.hist(heights, bins=50, alpha=0.7, label='Heights')\n",
    "plt.xlabel('Pixels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Image Dimensions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46487ac5",
   "metadata": {},
   "source": [
    "# Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748f155",
   "metadata": {},
   "source": [
    "## Build mapping for Dataset 1 (YOLO Roboflow dataset)\n",
    "Parse `data.yaml` to extract class names and then scan YOLO label files. Only include images with a single object (single-line label files) to build an image->class mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea077c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary of single-object images (absolute path -> class name) for Roboflow YOLO dataset (dataset1)\n",
    "\n",
    "dataset1_root = Path(r\"dataset1\")\n",
    "# Parse data.yaml manually (simple since small)\n",
    "yaml_path = dataset1_root / \"data.yaml\"\n",
    "raw_yaml = yaml_path.read_text(encoding=\"utf-8\")\n",
    "# Extract names list using regex fallback\n",
    "names_match = re.search(r\"names:\\s*\\[(.*?)\\]\", raw_yaml, re.DOTALL)\n",
    "if not names_match:\n",
    "    raise ValueError(\"Could not find names list in data.yaml\")\n",
    "# Split respecting quotes\n",
    "names_part = names_match.group(1)\n",
    "class_names = [n.strip().strip(\"'\\\"\") for n in names_part.split(',')]\n",
    "\n",
    "# Directories relative to data.yaml spec (they use .. relative to data.yaml location)\n",
    "# Compute absolute paths for train/valid/test images & labels\n",
    "train_images_dir = dataset1_root / \"train\" / \"images\"\n",
    "valid_images_dir = dataset1_root / \"valid\" / \"images\"\n",
    "test_images_dir  = dataset1_root / \"test\" / \"images\"\n",
    "train_labels_dir = dataset1_root / \"train\" / \"labels\"\n",
    "valid_labels_dir = dataset1_root / \"valid\" / \"labels\"\n",
    "test_labels_dir  = dataset1_root / \"test\" / \"labels\"\n",
    "\n",
    "def find_image_for_label(label_file: Path) -> Path | None:\n",
    "    stem = label_file.stem  # YOLO: same stem\n",
    "    for ext in ('.jpg', '.jpeg', '.png'):  # common\n",
    "        for parent in (train_images_dir, valid_images_dir, test_images_dir):\n",
    "            candidate = parent / f\"{stem}{ext}\"\n",
    "            if candidate.exists():\n",
    "                return candidate\n",
    "    return None\n",
    "\n",
    "single_object_map = {}\n",
    "multiple_object_count = 0\n",
    "missing_image_count = 0\n",
    "\n",
    "def process_labels_dir(labels_dir: Path):\n",
    "    global multiple_object_count, missing_image_count\n",
    "    if not labels_dir.exists():\n",
    "        return\n",
    "    for lf in labels_dir.iterdir():\n",
    "        if not lf.is_file() or lf.suffix != '.txt':\n",
    "            continue\n",
    "        lines = [ln.strip() for ln in lf.read_text(encoding='utf-8').splitlines() if ln.strip()]\n",
    "        if len(lines) != 1:  # skip multi-object or empty\n",
    "            if len(lines) > 1:\n",
    "                multiple_object_count += 1\n",
    "            continue\n",
    "        # Single line: class_idx xc yc w h\n",
    "        parts = lines[0].split()\n",
    "        if not parts:\n",
    "            continue\n",
    "        try:\n",
    "            class_idx = int(parts[0])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if not (0 <= class_idx < len(class_names)):\n",
    "            continue\n",
    "        img_path = find_image_for_label(lf)\n",
    "        if img_path is None:\n",
    "            missing_image_count += 1\n",
    "            continue\n",
    "        single_object_map[str(img_path.resolve())] = class_names[class_idx]\n",
    "\n",
    "for d in (train_labels_dir, valid_labels_dir, test_labels_dir):\n",
    "    process_labels_dir(d)\n",
    "\n",
    "print(f\"Total single-object images: {len(single_object_map)}\")\n",
    "print(f\"Skipped (multi-object) label files: {multiple_object_count}\")\n",
    "print(f\"Missing image files: {missing_image_count}\")\n",
    "# Show sample\n",
    "for i, (p, lbl) in enumerate(list(single_object_map.items())[:10]):\n",
    "    print(f\"{i+1}. {p} -> {lbl}\")\n",
    "\n",
    "# Persist\n",
    "out_json = 'dataset1_labels.json'\n",
    "with open(out_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(single_object_map, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Saved dictionary to {out_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e9986",
   "metadata": {},
   "source": [
    "## EDA: image dimension distributions (Dataset 1)\n",
    "Sample images and visualize width/height distributions to inform cropping/resizing strategy for dataset 1 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31515784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again find and plot the distribution of image dimensions in the single_object_map\n",
    "import random\n",
    "from PIL import Image\n",
    "with open('dataset1_labels.json', 'r', encoding='utf-8') as f:\n",
    "    single_object_map = json.load(f)\n",
    "\n",
    "sample_paths = random.sample(list(single_object_map.keys()), 3000)\n",
    "dimensions = []\n",
    "for path in sample_paths:\n",
    "    with Image.open(path) as img:\n",
    "        dimensions.append(img.size)  # (width, height)\n",
    "widths, heights = zip(*dimensions)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Image Width Distribution (Dataset 1)')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=20, color='green', alpha=0.7)\n",
    "plt.title('Image Height Distribution (Dataset 1)')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281e593",
   "metadata": {},
   "source": [
    "## Crop 256x256 regions around labeled bounding boxes (Dataset 1)\n",
    "For each single-object image, read its YOLO label, compute the sign center in pixel coordinates, and crop a 256x256 patch centered on the sign. Save crops to `dataset1_cropped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f38aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop 256x256 regions around traffic signs from 416x416 images in dataset1\n",
    "# Save cropped images to a new directory with the same filenames\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Load the dataset1 labels\n",
    "with open('dataset1_labels.json', 'r', encoding='utf-8') as f:\n",
    "    dataset1_labels = json.load(f)\n",
    "\n",
    "dataset1_root = Path(r\"dataset1\")\n",
    "output_dir = Path(r\"dataset1_cropped\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Label directories to search for corresponding txt files\n",
    "label_dirs = [\n",
    "    dataset1_root / \"train\" / \"labels\",\n",
    "    dataset1_root / \"test\" / \"labels\"\n",
    "]\n",
    "\n",
    "def find_label_file(image_path: Path) -> Path | None:\n",
    "    \"\"\"Find the corresponding YOLO label txt file for an image.\"\"\"\n",
    "    stem = image_path.stem\n",
    "    for label_dir in label_dirs:\n",
    "        label_file = label_dir / f\"{stem}.txt\"\n",
    "        if label_file.exists():\n",
    "            return label_file\n",
    "    return None\n",
    "\n",
    "def get_bbox_from_label(label_file: Path) -> tuple | None:\n",
    "    \"\"\"Parse YOLO label file and return (x_center, y_center, width, height) normalized.\"\"\"\n",
    "    lines = [ln.strip() for ln in label_file.read_text(encoding='utf-8').splitlines() if ln.strip()]\n",
    "    if len(lines) != 1:\n",
    "        return None\n",
    "    parts = lines[0].split()\n",
    "    if len(parts) < 5:\n",
    "        return None\n",
    "    try:\n",
    "        x_center = float(parts[1])\n",
    "        y_center = float(parts[2])\n",
    "        width = float(parts[3])\n",
    "        height = float(parts[4])\n",
    "        return (x_center, y_center, width, height)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def crop_around_bbox(img: Image.Image, bbox: tuple, crop_size: int = 256) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Crop a crop_size x crop_size region centered on the bounding box.\n",
    "    If the crop would go outside image bounds, shift it to stay within bounds.\n",
    "    \"\"\"\n",
    "    img_width, img_height = img.size\n",
    "    x_center_norm, y_center_norm, _, _ = bbox\n",
    "    \n",
    "    # Convert normalized bbox center to pixel coordinates\n",
    "    x_center_px = int(x_center_norm * img_width)\n",
    "    y_center_px = int(y_center_norm * img_height)\n",
    "    \n",
    "    # Calculate crop boundaries centered on bbox\n",
    "    half_crop = crop_size // 2\n",
    "    left = x_center_px - half_crop\n",
    "    top = y_center_px - half_crop\n",
    "    right = left + crop_size\n",
    "    bottom = top + crop_size\n",
    "    \n",
    "    # Shift crop if it goes outside image bounds\n",
    "    if left < 0:\n",
    "        left = 0\n",
    "        right = crop_size\n",
    "    if top < 0:\n",
    "        top = 0\n",
    "        bottom = crop_size\n",
    "    if right > img_width:\n",
    "        right = img_width\n",
    "        left = img_width - crop_size\n",
    "    if bottom > img_height:\n",
    "        bottom = img_height\n",
    "        top = img_height - crop_size\n",
    "    \n",
    "    # Ensure bounds are valid (for images smaller than crop_size)\n",
    "    left = max(0, left)\n",
    "    top = max(0, top)\n",
    "    right = min(img_width, right)\n",
    "    bottom = min(img_height, bottom)\n",
    "    \n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "# Process all images in dataset1_labels\n",
    "success_count = 0\n",
    "skip_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for img_path_str, label in dataset1_labels.items():\n",
    "    img_path = Path(img_path_str)\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        error_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Find corresponding label file\n",
    "    label_file = find_label_file(img_path)\n",
    "    if label_file is None:\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Get bounding box\n",
    "    bbox = get_bbox_from_label(label_file)\n",
    "    if bbox is None:\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            # Only process 416x416 images (or close to it)\n",
    "            if img.size[0] < 256 or img.size[1] < 256:\n",
    "                skip_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Crop around the traffic sign\n",
    "            cropped = crop_around_bbox(img, bbox, crop_size=256)\n",
    "            \n",
    "            # Save with same filename to output directory\n",
    "            output_path = output_dir / img_path.name\n",
    "            cropped.save(output_path)\n",
    "            success_count += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_count += 1\n",
    "        print(f\"Error processing {img_path.name}: {e}\")\n",
    "\n",
    "print(f\"Successfully cropped: {success_count}\")\n",
    "print(f\"Skipped: {skip_count}\")\n",
    "print(f\"Errors: {error_count}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85dd46",
   "metadata": {},
   "source": [
    "## Update dataset1 label paths to point to cropped images\n",
    "Replace original image paths in `dataset1_labels.json` with the paths to the newly created cropped images. Warnings are printed for any missing cropped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataset1_labels.json to point to the cropped images instead of the originals\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load current labels\n",
    "with open('dataset1_labels.json', 'r', encoding='utf-8') as f:\n",
    "    dataset1_labels = json.load(f)\n",
    "\n",
    "cropped_dir = Path(r\"dataset1_cropped\")\n",
    "\n",
    "# Create new dictionary with updated paths\n",
    "updated_labels = {}\n",
    "for old_path, label in dataset1_labels.items():\n",
    "    old_path_obj = Path(old_path)\n",
    "    new_path = cropped_dir / old_path_obj.name\n",
    "    if new_path.exists():\n",
    "        updated_labels[str(new_path.resolve())] = label\n",
    "    else:\n",
    "        print(f\"Warning: cropped image not found: {new_path.name}\")\n",
    "\n",
    "# Save updated labels\n",
    "with open('dataset1_labels.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(updated_labels, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Updated {len(updated_labels)} paths to point to cropped images\")\n",
    "print(f\"Sample: {list(updated_labels.keys())[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634742b",
   "metadata": {},
   "source": [
    "## Verify cropped image dimensions (Dataset 1)\n",
    "Plot the distribution of the cropped images to ensure crop_size = 256 was applied as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ef49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the distribution of image dimensions in the cropped dataset1_labels.json\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "with open('dataset1_labels.json', 'r', encoding='utf-8') as f:\n",
    "    dataset1_labels = json.load(f)  \n",
    "sample_paths = random.sample(list(dataset1_labels.keys()), 3000)\n",
    "dimensions = [] \n",
    "for path in sample_paths:\n",
    "    with Image.open(path) as img:\n",
    "        dimensions.append(img.size)  # (width, height)\n",
    "widths, heights = zip(*dimensions)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=20, color='blue', alpha=0.7)\n",
    "plt.title('Cropped Image Width Distribution (Dataset 1)')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=20, color='green', alpha=0.7)\n",
    "plt.title('Cropped Image Height Distribution (Dataset 1)')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb653b76",
   "metadata": {},
   "source": [
    "# Merge the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684c408",
   "metadata": {},
   "source": [
    "* A basic problem is the mismatch in how each dataset labels the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45848c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a list of the distinct class labels in dataset1_labels.json\n",
    "with open('dataset1_labels.json', 'r', encoding='utf-8') as f:\n",
    "    dataset1_labels = json.load(f)\n",
    "distinct_labels = set(dataset1_labels.values())\n",
    "print(f\"Distinct class labels in dataset1_labels.json ({len(distinct_labels)} total):\")\n",
    "for lbl in sorted(distinct_labels):\n",
    "    print(f\"- {lbl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6868966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a list of the unique labels in both dataset2_labels.json\n",
    "with open('dataset2_labels.json', 'r', encoding='utf-8') as f:\n",
    "    dataset2_labels = json.load(f)\n",
    "distinct_labels2 = set(dataset2_labels.values())\n",
    "print(f\"Distinct class labels in dataset2_labels.json ({len(distinct_labels2)} total):\")\n",
    "for lbl in sorted(distinct_labels2):\n",
    "    print(f\"- {lbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7fc62",
   "metadata": {},
   "source": [
    "* Basically the only difference is on the speed limit signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map different spellings/wordings to a single canonical label\n",
    "# Only include things that should be merged across datasets.\n",
    "synonym_map_lower = {\n",
    "    # Speed limits that appear in both datasets\n",
    "    \"speed limit (30km/h)\": \"Speed Limit 30\",\n",
    "    \"speed limit (40km/h)\": \"Speed Limit 40\",\n",
    "    \"speed limit (50km/h)\": \"Speed Limit 50\",\n",
    "    \"speed limit (60km/h)\": \"Speed Limit 60\",\n",
    "    \"speed limit (70km/h)\": \"Speed Limit 70\",\n",
    "    \"speed limit (80km/h)\": \"Speed Limit 80\",\n",
    "\n",
    "    # If you ever had \"speed limit (15km/h)\" <-> \"Speed Limit 15\"\n",
    "    # you could add:\n",
    "    # \"speed limit (15km/h)\": \"Speed Limit 15\",\n",
    "}\n",
    "\n",
    "def unify_label(label: str) -> str:\n",
    "    \"\"\"\n",
    "    Return the unified/canonical version of a label.\n",
    "    - If it's a known alias, map to the canonical form.\n",
    "    - Otherwise leave it exactly as-is.\n",
    "    \"\"\"\n",
    "    key = label.strip().lower()\n",
    "    return synonym_map_lower.get(key, label)\n",
    "\n",
    "# Build new dict with ALL keys from both datasets,\n",
    "# values replaced with unified labels.\n",
    "merged_labels = {}\n",
    "\n",
    "# First add all dataset1 labels\n",
    "for k, v in dataset1_labels.items():\n",
    "    merged_labels[k] = unify_label(v)\n",
    "\n",
    "# Then add all dataset2 labels\n",
    "for k, v in dataset2_labels.items():\n",
    "    merged_labels[k] = unify_label(v)\n",
    "\n",
    "# Save to a new JSON file\n",
    "with open('merged_labels.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(merged_labels, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Merged labels written to merged_labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace absolute paths in merged_labels.json with relative paths\n",
    "\n",
    "infile = 'merged_labels.json'\n",
    "if not Path(infile).exists():\n",
    "    print(f\"{infile} not found — nothing to update.\")\n",
    "else:\n",
    "    with open(infile, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    updated = {}\n",
    "    for key, val in data.items():\n",
    "        try:\n",
    "            p = Path(key)\n",
    "            if p.is_absolute():\n",
    "                rel = os.path.relpath(str(p), start=os.getcwd())\n",
    "                # normalize separators to forward-slash for consistency\n",
    "                rel = rel.replace('\\\\', '/')\n",
    "                updated[rel] = val\n",
    "            else:\n",
    "                updated[key] = val\n",
    "        except Exception:\n",
    "            # If any unexpected path, keep original key\n",
    "            updated[key] = val\n",
    "\n",
    "    with open(infile, 'w', encoding='utf-8') as f:\n",
    "        json.dump(updated, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Updated {len(updated)} entries in {infile} — absolute paths converted where possible.\")\n",
    "    # show a small sample\n",
    "    for i, k in enumerate(list(updated.keys())[:10]):\n",
    "        print(f\"{i+1}. {k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
